# Summary

## Breakdown
* Part 1 - Data preprocessing - Completed on 04-07-2020
* Part 2 - Regression - Currently pursuing
    * Simple Linear regression - Completed on 06-07-2020
    * Multiple Linear regression - Completed on 20-07-2020
    * Polynomial Regression - Completed on 23-07-2020
    * Support Vector Regression - Currently pursuing


## Doubts
* Splitting data into test and training sets -> Why not CV as per andrew NG?
* Why using same scaler instance on both training and test set in feature scaling? -> Asked on 04-07-2020
* Assumptions of linear regression -> Linearity , Homoscedasticity, Multivariate normality, Independance of errors,Lack of multicollinearity
* Question on instance unsolved.
* 

## Important Links
* [Datasets and code google drive link](https://drive.google.com/drive/folders/1OFNnrHRZPZ3unWdErjLHod8Ibv2FfG1d)
* [M L Summary and FAQ PDF](./material/Machine_Learning_A_Z_Q_A.pdf)

## Todo:
* [Multi linear Regression Backward elimination bonus -1](https://www.dropbox.com/sh/pknk0g9yu4z06u7/AADSTzieYEMfs1HHxKHt9j1ba?dl=0)
* [Multi linear regression Bonus Exercise 2](https://www.superdatascience.com/pages/ml-regression-bonus-2)
* Least Square Difference and Support Vector Regression reading
* Least Square - Find literature
* [SVR  - additional reading](https://core.ac.uk/download/pdf/81523322.pdf)



> .ipynb python notebooks can be opened using Anaconda IDE and Jupyter / Spyder notebooks or google colab.