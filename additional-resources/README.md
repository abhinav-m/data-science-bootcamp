# Additional resources

> A list of additional resources / references and todos



## Todo:

### Udemy (Super data science is by same authors):
* [Multi linear Regression Backward elimination bonus -1](https://www.dropbox.com/sh/pknk0g9yu4z06u7/AADSTzieYEMfs1HHxKHt9j1ba?dl=0)
* [Multi linear regression Bonus Exercise 2](https://www.superdatascience.com/pages/ml-regression-bonus-2)
* [Blog for understanding regression and classification](https://www.superdatascience.com/blogs/the-ultimate-guide-to-regression-classification) - Done on 05-10-2020
* [Practical case study - Logistic Regression](http://iamtrask.github.io/2015/07/12/basic-python-network/)
* [Classification Pros Cons](./material/Classification_Pros_Cons.pdf) //FIXME
* [Clustering Pros Cons](./material/Clustering-Pros-Cons.pdf)
* [NLP with BERT course](https://www.udemy.com/course/natural-language-processing-with-bert/learn/lecture/18889310#overview)
* [Homework challenge NLP](https://www.udemy.com/course/machinelearning/learn/lecture/6085634#overview)
* [Ultimate guide to ANN](https://www.superdatascience.com/blogs/the-ultimate-guide-to-artificial-neural-networks-ann)
* [ANN for regression free course](https://www.udemy.com/cart/subscribe/course/2968824/)
* [CNN - Bonus Resources](https://www.superdatascience.com/blogs/the-ultimate-guide-to-convolutional-neural-networks-cnn)
* [LDA explanation](https://www.udemy.com/course/machinelearning/learn/lecture/20141692#overview)
* [Cat boost](https://www.superdatascience.com/pages/ml-model-selection-bonus)


## Blogs / Books:
* [SVR  - additional reading](https://core.ac.uk/download/pdf/81523322.pdf)
* [Kernel codes in C#](https://github.com/accord-net/framework/tree/development/Sources/Accord.Statistics/Kernels)
* [Types of Kernels - Kernel SVMS](http://crsouza.com/2010/03/17/kernel-functions-for-machine-learning-applications/) -> Currently pursuing
* [Types of Kernels - Kernel SVMS](https://datafreakankur.com/machine-learning-kernel-functions-3d-visualization/) -> Completed on 06-10-2020
* [NLP with BERT guide](https://sdsclub.com/bert-google-nlp-algorithm/)
* [Efficient BackProp by Yann LeCun 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)
* [Deep sparse rectifier neural networks](http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf)
* [Basic Neural Network](http://iamtrask.github.io/2015/07/12/basic-python-network/)
* [Neural network in 13 lines of python](https://iamtrask.github.io/2015/07/27/python-network-part2/)
* [Cost function in neural networks along with their applications](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications)
* [Neural networks and deep learning - how gradient descent works](http://neuralnetworksanddeeplearning.com/chap2.html) 
* [Gradient based learning applied to document recognition - Yann Lecun](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.138.1115)
* [Introduction to CNN](https://cs.nju.edu.cn/wujx/teaching/15_CNN.pdf)
* [CNN](https://cs.nju.edu.cn/wujx/)
* [Gimp Conv Matrix](docs.gimp.org/en/plug-in-convmatrix.html)
* [Understanding CNN with mathematical models](https://arxiv.org/abs/1609.04112)
* [Delving Deep into rectifiers](https://arxiv.org/abs/1502.01852)
* [Evaluation of Pooling operations](http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf)
* [Deep learning papers](https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)
* [A friendly introduction to Cross-Entropy Loss](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)
* [PCA visualization explanation](https://setosa.io/ev/principal-component-analysis/) -> Completed on 06-10-2020
* [MIT opencourseware least squares](https://www.youtube.com/watch?v=YwZYSTQs-Hk) -> Completed on 05-10-2020
* [Least Squares explanation](https://docs.google.com/document/d/1vXgizn0Zz5VM_mTEfrRqwydfCyn0OY5DNlkieFLRU68/edit) -> Completed on 05-10-2020
* [Stats through visualization](https://setosa.io/ev/)
    * Read through PCA - 02-01-2021
* [Bayes Theorem and probability](https://www.analyticsvidhya.com/blog/2017/03/conditional-probability-bayes-theorem/) 
* [Time series analysis](https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775) -> Currently reviewing
* [Different types of outliers](https://www.anodot.com/blog/quick-guide-different-types-outliers/)
* [Probability Density functions](https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-continuous/v/probability-density-functions)
* [Pearsons correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)

## Statistics 
* [Poisson Distribution](https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459)
* [Geometric Distribution](https://www.math.umd.edu/~millson/teaching/STAT400fall18/slides/article8.pdf)
* [Negative Binomial Distribution](https://www.sciencedirect.com/topics/mathematics/negative-binomial-distribution)
* [Sample variance](https://web.ma.utexas.edu/users/mks/M358KInstr/SampleSDPf.pdf)
* [How exit polling works](https://mathforgrownups.com/exit-polling-a-statistics-refresher/)
* [Exit polling 2](https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/firth/exit-poll-explainer/)
* [Type 1 and Type 2 errors in hypothesis testing](https://statisticsbyjim.com/hypothesis-testing/types-errors-hypothesis-testing/) - Read on 01-01-2021 (ReRead)
* [Representative Sampling vs Random Sampling](https://statisticsbyjim.com/hypothesis-testing/types-errors-hypothesis-testing/) - Wrong link (Correct)
* [Khan Academy mean and variance of bernoulli distribution](https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/binomial-mean-standard-dev-formulas/v/mean-and-variance-of-bernoulli-distribution-example)
* [Khan Academy - Statistics](https://www.khanacademy.org/math/statistics-probability)
* [A-B Testing](https://www.optimizely.com/optimization-glossary/ab-testing/) -> Done 30-12-2020
* [A-B Testing examples](https://blog.optimizely.com/2015/06/04/ecommerce-conversion-optimization-case-studies/) -> Done 01-01-2021
* [Chi Squared Test](https://www.youtube.com/watch?v=jABsbNBPXIk&feature=youtu.be&ab_channel=KhanAcademy)
* [Penn State - Hypothesis Testing](https://online.stat.psu.edu/stat200/lesson/10/10.2)
* [ANOVA test](https://www.khanacademy.org/math/statistics-probability/analysis-of-variance-anova-library)
* [Z score](https://www.youtube.com/watch?v=Oyjp6Ke8V9I&t=98s&ab_channel=KariAlexander)

## To find:
* Upper confidence bound - Regret whitepaper - Austria
* Applying dimensionality reduction on sample datasets
* Least Square Difference and Support Vector Regression reading
* Least Square - Find literature
* R Square adjusted - notes
* CAP curve and CAP curve analysis notes
