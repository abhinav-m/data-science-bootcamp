# Summary

## Breakdown
* Part 1 - Data preprocessing - Completed on 04-07-2020
* Part 2 - Regression - Completed on 06-08-2020
    * Simple Linear regression - Completed on 06-07-2020
    * Multiple Linear regression - Completed on 20-07-2020
    * Polynomial Regression - Completed on 23-07-2020
    * Support Vector Regression - Completed on 25-07-2020
    * Decision Tree Regression - Completed on 27-07-2020 
    * Random forest Regression - Completed on 29-07-2020
    * Evaluating Regression Models performance - Completed on 04-08-2020
    * Choosing a regression model - Completed on 06-08-2020
* Part 3 - Classification - Completed on 04-09-2020
    * Logistic Regression - Completed on 08-08-2020
    * K Nearest Neighbours - Completed on 09-08-2020 
    * SVM - Completed on 17-08-2020
    * Kernel SVM - Completed on 20-08-2020
    * Naive Bayes - Completed on 23-08-2020
    * Decision Trees - Completed on 25-08-2020
    * Random Forest - Completed on 28-08-2020
    * Evaluating classification models performance- Completed on 03-09-2020
    * Classification Model template performance comparison - Completed on 04-09-2020
* Part 4 - Clustering - Completed on - 10-09-2020
    * K - Means -Clustering - Completed on - 09-09-2020
    * Heirarchical Clustering - Completed on - 10-09-2020
* Part 5 - Association Rule Learning- 14-09-2020
    * Apriori - Completed on 13-09-2020
    * Eclat - Completed on 14-09-2020
* Part 6 - Reinforcement Learning - Completed on 19-09-2020
    * Upper Confidence Bound - Completed on 17-09-2020
    * Thompson Sampling - Completed on 19-09-2020
* Part 7 - Natural Language Processing - Completed on 24-09-2020
    * Bag of words model - Completed on 24-09-2020
* Part 8 - Deep Learning - Completed on 28-09-2020
    * Artificial Neural Networks - Completed on 26-09-2020
    * Convolutional Neural Networks - Completed on 28-09-2020
* Part 9 - Dimensionality Reduction - Completed on 30-09-2020
    * Principal Component Analysis - Completed on 29-09-2020
    * Linear Discriminant Analysis - Completed on 30-09-2020
    * Kernel - PCA - Completed on 30-09-2020
* Part 10 - Model Selection and boosting - Completed on 01-10-2020
    * K fold cross validation - Completed on 01-10-2020
    * Grid Search - Completed on 01-10-2020
    * XG Boost - Completed on 01-10-2020
  
## Doubts
* Splitting data into test and training sets -> Why not CV as per andrew NG?
* Why using same scaler instance on both training and test set in feature scaling? -> Asked on 04-07-2020
* Assumptions of linear regression -> Linearity , Homoscedasticity, Multivariate normality, Independance of errors,Lack of multicollinearity
* Question on instance unsolved.

## Important Links
* [Datasets and code google drive link](https://drive.google.com/drive/folders/1OFNnrHRZPZ3unWdErjLHod8Ibv2FfG1d)
* [Classification / Regression templates for performance evaluation / model selection](https://drive.google.com/drive/folders/1O8vabaxga3ITjCWfwD79Xnyf8RavYuyk)
* [M L Summary and FAQ PDF](./material/Machine_Learning_A_Z_Q_A.pdf)
* [Regression Models Pros / Cons](./material/Classification_Pros_Cons.pdf)
* [Classification Models Pros / Cons](./material/Classification_Pros_Cons.pdf)
* [Upper confidence bound algorithm](./material/UCB_Algorithm_Slide.png)
* [Thompson sampling algorithm](./material/Thompson_Sampling_Slide.png)

> .ipynb python notebooks can be opened using Anaconda IDE and Jupyter / Spyder notebooks or google colab.